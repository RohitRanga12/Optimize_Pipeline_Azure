{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name: quick-starts-ws-206916\nAzure region: southcentralus\nSubscription id: 61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\nResource group: aml-quickstarts-206916\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1662795494798
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "cluster_name = \"optimize-pipeline-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # To use a different region for the compute, add a location='<region>' parameter\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "InProgress.\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1662795780822
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
        "from azureml.core import Environment, ScriptRunConfig\n",
        "import os\n",
        "\n",
        "# Specify parameter sampler\n",
        "ps = RandomParameterSampling( {\n",
        "        \"C\": uniform(0.00001, 1),\n",
        "        \"max_iter\": choice(50,100,150,200),\n",
        "    }\n",
        ")\n",
        "\n",
        "# Specify a Policy\n",
        "policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "# Setup environment for your training run\n",
        "sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='conda_dependencies.yml')\n",
        "\n",
        "# Create a ScriptRunConfig Object to specify the configuration details of your training job\n",
        "src = ScriptRunConfig(source_directory=\"Users/odl_user_206916/\",\n",
        "                      script='train.py',\n",
        "                      compute_target=cpu_cluster,\n",
        "                      environment=sklearn_env)\n",
        "\n",
        "# Create a HyperDriveConfig using the src object, hyperparameter sampler, and policy.\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                             hyperparameter_sampling=ps,\n",
        "                             policy=policy,\n",
        "                             primary_metric_name=\"accuracy\",\n",
        "                             primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                             max_total_runs=100,\n",
        "                             max_concurrent_runs=4)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1662796369628
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "\n",
        "hyperdrive_run = exp.submit(hyperdrive_config)\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Users/odl_user_206916/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Submit your hyperdrive run to the experiment and show run details with the widget.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m hyperdrive_run \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperdrive_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/experiment.py:238\u001b[0m, in \u001b[0;36mExperiment.submit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m submit_func \u001b[38;5;241m=\u001b[39m get_experiment_submit(config)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmit config \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)):\n\u001b[0;32m--> 238\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43msubmit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     run\u001b[38;5;241m.\u001b[39mset_tags(tags)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/hyperdrive/_search.py:141\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(hyperdrive_config, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m workspace_auth \u001b[38;5;241m=\u001b[39m workspace\u001b[38;5;241m.\u001b[39m_auth_object\n\u001b[1;32m    139\u001b[0m host_url \u001b[38;5;241m=\u001b[39m hyperdrive_config\u001b[38;5;241m.\u001b[39m_get_host_url(workspace\u001b[38;5;241m=\u001b[39mworkspace, run_name\u001b[38;5;241m=\u001b[39mexperiment_name)\n\u001b[0;32m--> 141\u001b[0m experiment_dto \u001b[38;5;241m=\u001b[39m \u001b[43m_create_experiment_dto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperdrive_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtelemetry_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivity_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m temporary_config:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/hyperdrive/_search.py:43\u001b[0m, in \u001b[0;36m_create_experiment_dto\u001b[0;34m(hyperdrive_config, workspace, experiment_name, telemetry_values, activity_logger, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hyperdrive_config\u001b[38;5;241m.\u001b[39msource_directory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     snapshot_client \u001b[38;5;241m=\u001b[39m SnapshotsClient(workspace\u001b[38;5;241m.\u001b[39mservice_context)\n\u001b[0;32m---> 43\u001b[0m     snapshot_id \u001b[38;5;241m=\u001b[39m \u001b[43msnapshot_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_snapshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperdrive_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m activity_logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         activity_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSnapshot was created. SnapshotId=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, snapshot_id)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_restclient/snapshots_client.py:98\u001b[0m, in \u001b[0;36mSnapshotsClient.create_snapshot\u001b[0;34m(self, file_or_folder_path, retry_on_failure, raise_on_validation_failure)\u001b[0m\n\u001b[1;32m     95\u001b[0m     parent_root, parent_snapshot_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mget_latest_snapshot()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Compute the dir tree for the current working set\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m curr_root \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_merkletree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_or_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Compute the diff between the two dirTrees\u001b[39;00m\n\u001b[1;32m    101\u001b[0m entries \u001b[38;5;241m=\u001b[39m compute_diff(parent_root, curr_root)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_base_sdk_common/merkle_tree.py:21\u001b[0m, in \u001b[0;36mcreate_merkletree\u001b[0;34m(file_or_folder_path, exclude_function)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_merkletree\u001b[39m(file_or_folder_path, exclude_function):\n\u001b[1;32m     20\u001b[0m     root \u001b[38;5;241m=\u001b[39m DirTreeNode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 21\u001b[0m                        datetime\u001b[38;5;241m.\u001b[39mfromtimestamp(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetmtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_or_folder_path\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39misoformat())\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(file_or_folder_path):\n\u001b[1;32m     23\u001b[0m         folder_path \u001b[38;5;241m=\u001b[39m file_or_folder_path\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/genericpath.py:55\u001b[0m, in \u001b[0;36mgetmtime\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetmtime\u001b[39m(filename):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the last modification time of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_mtime\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Users/odl_user_206916/'"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1662796370795
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Get your best run and save the model from that run.\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598276310862
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data\n",
        "\n",
        "# Use the clean_data function to clean your data.\n",
        "x, y = clean_data(### YOUR DATA OBJECT HERE ###)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598275726969
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=,\n",
        "    primary_metric=,\n",
        "    training_data=,\n",
        "    label_column_name=,\n",
        "    n_cross_validations=)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598275665403
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your automl run\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}